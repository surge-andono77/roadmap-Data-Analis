ROADMAP DATA ANALYST — ENTERPRISE GRADE
1. FUNDAMENTALS ( pondasi wajib )
  Outcome: bisa membaca data, memahami konteks bisnis, dan siap masuk workflow analytics. 
  Artinya, membentuk mindset analis, memahami bisnis, dan menguasai alat dasar sebelum masuk ke teknik tingkat lanjut.
  Ini bukan teknis coding. Ini area yang membentuk cara berpikir seorang Data Analyst. 
    
  1.1. Business & Analytical Mindset → FOKUS: Cara Berpikir
    * Critical thinking: problem → hypothesis → data → insight.
        - Mulai dari problem, bukan data.
        - Rumuskan hypothesis.
        - Tentukan data apa yang diperlukan.
        - Tarik insight yang bisa dieksekusi.
    * KPI & Metrics: revenue, churn, retention, CAC, LTV, conversion funnel.
      Data Analyst harus paham:
      	- revenue
      	- churn
      	- retention
      	- conversion funnel
      	- CAC, LTV
      	- operasi, sales, marketing metrics
        Tujuannya: Agar saat dapat dataset, Anda tahu apa artinya dan kenapa itu penting untuk bisnis.
    * Domain knowledge: sales, marketing, finance, operations.
        Tanpa konteks bisnis, analis hanya jadi “data operator”, bukan “business partner”.
      
  1.2. Spreadsheet Mastery (Excel/Google Sheets)
    * VLOOKUP/XLOOKUP, INDEX-MATCH
    * Pivot Table
    * Conditional formatting
    * Basic charts
    Excel/Google Sheets melatih:
    	- mengolah data kecil/menengah
    	- eksplorasi cepat
    	- transformasi sederhana
    	- hitungan manual untuk validasi
    Tools seperti VLOOKUP, Pivot Table adalah versi ringan dari SQL/Python—membiasakan struktur berpikir tabular.
  > Ini baseline skill semua Data Analyst.
      
2. SQL MASTERCLASS ( core skill 80% pekerjaan )
  Outcome: mampu query data skala enterprise di warehouse (BigQuery, Snowflake, Redshift).

  2.1. SQL Dasar
    * SELECT, WHERE, ORDER BY
    * LIMIT, DISTINCT
  
  2.2. SQL Menengah
    * JOIN (inner, left, right, full)
    * GROUP BY + Aggregate
  
  2.3. SQL Advanced
    * Window Function (RANK, ROW_NUMBER, LAG, LEAD)
    * CTE & Subquery
    * Pivot/Unpivot
    * Performance tuning (index, clustering)
  > *SQL adalah skill paling krusial — tidak bisa dinegosiasikan.*
  Ini adalah tahap membentuk fondasi otak Data Analyst:
  - cara berpikir analitis
  - paham tujuan bisnis
  - bisa menginterpretasikan angka
  - bisa kerja cepat dengan Excel
  FUNDAMENTALS = Mindset + Business Understanding + Basic Tools

3. DATA MANIPULATION (Python)
    1. PYTHON FUNDAMENTALS FOR ANALYTICS (MANDATORY)
    DATA MANIPULATION (Python) yang enterprise-grade, komprehensif, dan langsung pakai di workflow Data Analyst profesional. Ini versi no-nonsense, fokus ke skill yang benar-benar dipakai di perusahaan.
    Tujuan utama: 
    - membentuk technical engine seorang Data Analyst untuk mengolah data dalam skala besar dan kompleks.
    - membentuk analis yang mampu ingest → clean → transform → enrich → prepare dataset secara efisien dan scalable.
    
    Tidak perlu jadi software engineer; cukup kuasai bagian yang langsung dipakai saat mengolah data.
    FOKUS UTAMA: Mengubah raw data → clean → structured → ready for analytics
    	Disini mempelajari hal-hal seperti:
    		- load dataset (CSV, Excel, SQL, JSON)
    		- cleaning (missing value, typo, outliers)
    		- transformation (merge, groupby, pivot, melt)
    		- feature engineering
    		- time series manipulation
    		- automation pipeline
    	Python di sini adalah alat produksi.
    
    Ini sudah teknis coding, algorithmic thinking, dan automation.
    
    1.1. Core Syntax
    	- Tipe data: int, float, str, bool
    	- Struktur data: list, tuple, set, dict
    	- Control flow: if, for, while
    	- List comprehension (sangat penting):
    		1. Apa itu List Comprehension?
    		Cara singkat, cepat, efisien untuk membuat list baru dari iterable (list, dictionary, range, dataframe rows, dsb.).
    		a. Tanpa list comprehension:
    			result = [ ]
    			for x in range(10):
    				result.append(x * 2)
    		b. Dengan list comprehension:
    			result = [x * 2 for x in range(10)]
    		
    		2. Struktur Dasar List Comprehension
    		Format umumnya: [new_element  for element in iterable  if condition]
    		contoh : 
    			nums = [n for n in range(10)]
    			evens = [n for n in range(10) if n % 2 == 0]
    		
    		3. Bagian-Bagian Penting List Comprehension
    			3.1. Expression (apa yang mau dibuat?)
    				
    				[x * 2 for x in range(5)]    # Expression-nya adalah x * 2.  
    				
    			3.2. Iterable (sumber data)
    				Paling umum:
    				- range()
    				- list
    				- tuple
    				- set
    				- dictionary
    				- hasil query API / file
    				
    				contoh : [x for x in [1,2,3,4]]
    
    			3.3. Condition (opsional, filter)
    				contoh : [x for x in range(10) if x % 2 == 0]  # Filter membantu analyst ketika ingin subset data dengan cepat.
    		
    		4. Use Case Praktis untuk Data Analyst
    			4.1. Cleaning Text
    				contoh : 
    					cities = [" Jakarta", "bandung ", " Surabaya "]
    					cleaned = [c.strip().lower() for c in cities]
    					
    			4.2. Convert String to Numeric
    				contoh :
    					prices = ["100", "200", "350"]
    					prices = [int(p) for p in prices]
    			
    			4.3 Extract Feature dari Raw Column
    				contoh :
    					emails = ["a@gmail.com", "b@yahoo.com"]
    					domains = [e.split("@")[1] for e in emails]
    					
    		5. List Comprehension dengan IF–ELSE
    			Format : [expr1 if condition else expr2 for item in iterable]
    				contoh : 
    					grades = [ "A" if s >= 85 else "B" for s in [90, 72, 88, 60] ]
    
    		6. Nested Loop (Comprehension Bertingkat)
    			Contoh membuat pasangan kombinasi:
    				pairs = [(x, y) for x in range(3) for y in range(3)]
    
    			Untuk Data Analyst (contoh join manual simple):
    				users = ["u1","u2"]
    				products = ["p1","p2","p3"]
    
    				combinations = [(u,p) for u in users for p in products]
    				
    		7. List Comprehension + Dictionary
    			7.1. Convert list → dictionary
    					nums = [1,2,3]
    					d = {n: n*n for n in nums}
    
    			7.2. Filter dictionary key / value
    					scores = {"andi":90, "budi":70, "cici":85}
    					passed = {k:v for k,v in scores.items() if v >= 80}
    
    		8. List Comprehension dalam Analisis Data (Real Enterprise Use Case)
    			
    			8.1. Transformasi data dari file CSV sebelum masuk Pandas
    					clean_rows = [
    						[col.strip() for col in row] 
    						for row in raw_rows
    					]
    			
    			8.2. Feature engineering sebelum dimasukkan ke model
    					length_feature = [len(text) for text in comments]
    
    			8.3. Menandai kategori user
    					segments = ["VIP" if r > 1_000_000 else "REGULAR" for r in revenues]
    
    			8.4. Flatten nested lists
    					nested = [[1,2],[3,4],[5,6]]
    					flat = [x for row in nested for x in row]
    
    		9. Best Practices
    			a. Gunakan list comprehension ketika:
    				- Transformasi simple & jelas
    				- Filtering cepat
    				- Extracting/deriving features
    
    			b. Hindari ketika:
    				- Logic terlalu kompleks
    				- Banyak nested loops (lebih dari 2)
    				- Mudah membuat bug
    
    			c. Prinsip enterprise:
    
    			Readable > Clever
    			Kalau terlalu rumit → pakai loop biasa.
    			
    1.2. Functions Best Practice
    	- Function parameter
    	- Default values
    	- Return multiple values
    	- Lambda function
    		df["score2"] = df["score"].apply(lambda x: x + 10)
    
    1.3. Error Handling (Wajib untuk robust analytics)
    	contoh : 
    		try:
    			df = pd.read_csv("data.csv")
    		except FileNotFoundError as e:
    			print("File tidak ditemukan:", e)
    
    2. NUMPY — FOUNDATION FOR FAST DATA OPERATIONS
    	NumPy dipakai untuk operasi numerik cepat. Walaupun Data Analyst jarang pakai rumit-rumit, bagian berikut wajib:
    
    2.1. Array Basics
    	- Create array
    	- Indexing & slicing
    	- Reshape
    
    2.2. Vectorized Operations (penting untuk kinerja)
    	a = np.array([1,2,3])
    	b = a * 10  # vectorized
    
    2.3. Aggregations
    	sum, mean, std, argmax, argmin
    	
    2.4. Boolean Masking
    	a[a > 5]
    
    3. PANDAS — THE REAL CORE OF DATA MANIPULATION
    	Ini skill yang membedakan junior analyst vs professional analyst.
    
    3.1. DATA INGESTION (READING & WRITING)
    	Wajib kuasai semua format:
    
    	3.1.1. CSV, Excel, JSON
    		df = pd.read_csv("data.csv")
    		df = pd.read_excel("data.xlsx")
    		df = pd.read_json("data.json")
    		
    	3.1.2. SQL
    		df = pd.read_sql("SELECT * FROM sales", conn)
    
    	3.1.3. Parquet (enterprise-grade)
    		df = pd.read_parquet("data.parquet")
    
    	3.1.4. Writing back
    			.to_csv()
    			.to_excel()
    			.to_parquet()
    
    3.2. DATA EXPLORATION (Data Profiling)
    	Skill wajib sebelum cleaning.
    		Checklist Analisis Awal
    			- df.head(), df.tail()
    			- df.info()
    			- df.describe()
    			- df.isnull().sum()
    			- df.nunique()
    			- df.sample()
    
    3.3. DATA CLEANING (THIS IS 70% OF THE JOB)
    	3.3.1. Handling Missing Values
    		Drop:
    			df.dropna(subset=["age"], inplace=True)
    		Fill:
    			df["age"].fillna(df["age"].median(), inplace=True)
    
    	3.3.2. Handling Duplicates
    		df.drop_duplicates(inplace=True)
    
    	3.3.3. Handling Data Types
    		df["date"] = pd.to_datetime(df["date"])
    		df["id"] = df["id"].astype(str)
    		df["price"] = df["price"].astype(float)
    		
    	3.3.4. Outlier Treatment
    		Z-Score:
    			df = df[(np.abs(stats.zscore(df["amount"])) < 3)]
    
    		IQR:
    			Q1 = df["amount"].quantile(0.25)
    			Q3 = df["amount"].quantile(0.75)
    			IQR = Q3 - Q1
    			df = df[(df["amount"] >= Q1 - 1.5*IQR) & (df["amount"] <= Q3 + 1.5*IQR)]
    			
    	3.3.5. Text Cleaning (sangat sering dipakai)
    		df["name"] = df["name"].str.strip().str.lower()
    		df["city"] = df["city"].str.replace("jakrta", "jakarta")
    
    3.4. DATA TRANSFORMATION (CORE ENGINE OF ANALYTICS)
    	3.4.1. Filtering & Conditional Selection
    		df[df["revenue"] > 100000]
    		df[(df["city"] == "jakarta") & (df["age"] > 30)]
    		
    	3.4.2. Sorting
    		df.sort_values("revenue", ascending=False)
    	
    	3.4.3. Column Operations
    			- Add new column
    			- Modify existing
    			- Drop column
    				df["revenue_per_user"] = df["revenue"] / df["users"]
    				df.drop(columns=["temp"], inplace=True)
    				
    	3.4.4. Apply / Map / Replace (SUPER IMPORTANT)
    		df["grade"] = df["score"].apply(lambda x: "A" if x > 90 else "B")
    		df["gender"] = df["gender"].map({"M": "Male", "F": "Female"})
    		df["city"].replace({"jkt": "jakarta"}, inplace=True)
    		
    	3.4.5. GroupBy + Aggregation (Daily Job of Analyst)
    		df.groupby("city")["revenue"].sum()
    		df.groupby(["city","segment"]).agg({
    			"revenue":"sum",
    			"user_id":"nunique"
    		})
    
    3.5. JOIN & MERGE (DATA ANALYST’S BEST WEAPON)
    	Penggabungan dataset adalah skill wajib.
    		df = pd.merge(df_sales, df_customer, on="customer_id", how="left")
    	Tipe merge:
    		- inner
    		- left (paling sering)
    		- right
    		- outer
    		
    3.6. PIVOT & UNPIVOT (WAJIB UNTUK DASHBOARDING)
    	a. Pivot:
    		df.pivot_table(values="revenue", index="city", columns="month", aggfunc="sum")
    	
    	b. Melt (Unpivot):
    		df.melt(id_vars=["city"], var_name="month", value_name="revenue")
    
    3.7. TIME SERIES MANIPULATION
    	Aplikasi bisnis: sales analytics, forecasting, retention.
    	Parsing date:
    		df["date"] = pd.to_datetime(df["date"])
    
    	Extract periods:
    		df["year"] = df["date"].dt.year
    		df["month"] = df["date"].dt.month
    		df["weekday"] = df["date"].dt.day_name()
    		
    	contoh : 
    		df.resample("M", on="date")["revenue"].sum()
    
    3.8. FEATURE ENGINEERING (LEVEL ADVANCED)
    	Contoh fitur yang menaikkan level analis:
    		- Ratio features
    		- Lag features
    		- Rolling features
    		- Binning
    		- Categorization
    		df["rolling_7d"] = df["revenue"].rolling(7).mean()
    
    3.9. AUTOMATION FOR ANALYST
    	Looping over files:
    		import glob
    		files = glob.glob("data/*.csv")
    		df = pd.concat((pd.read_csv(f) for f in files))
    	Scheduled processing template
    		- Read data
    		- Clean
    		- Transform
    		- Export dashboard-ready file
    
    4. BEST PRACTICES FOR ENTERPRISE ANALYTICS
    4.1. Clean code standard
    		- No hardcode
    		- No magic number
    		- Use function
    		- Clear naming: order_date, total_revenue, customer_id
    
    4.2. Reproducible pipeline
    		- Script jadi modular
    		- Bisa dijalankan ulang kapan saja
    		- Konsisten
    
    4.3. Documentation
    		- Notebook harus rapi
    		- Insight jelas
    		- Ada langkah cleaning
    
    5. PROJECT-BASED LEARNING (Wajib untuk jadi profesional)
    	Rekomendasikan 5 project:
    		a. Project 1 — Data Cleaning Heavy
    			- Dataset kotor: missing, typo, outlier.
    
    		b. Project 2 — Customer Analytics
    			- Join multi-table
    			- GroupBy
    			- Cohort
    			
    		c. Project 3 — Sales Performance
    			- Time series
    			- KPI
    			- Rolling metrics
    			
    		d. Project 4 — Data Preparation for Dashboard
    			- Pivot tables
    			- Aggregation per segment & region
    			
    		e. Project 5 — Automated Data Pipeline
    			- Ambil raw data → bersihkan → simpan file siap Power BI
4. EDA — Exploratory Data Analysis
5. DATA VISUALIZATION & STORYTELLING
6. STATISTICS FOR ANALYTICS
7. BUSINESS ANALYTICS (mid-level skill)
8. DATA WAREHOUSE & BI PIPELINE
9. PRODUCTIVITY & ENTERPRISE SKILLS
10. PORTFOLIO BUILDING (wajib kalau mau cepat dapat kerja)
